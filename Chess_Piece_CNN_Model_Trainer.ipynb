{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGrS7Tb23nO3iLJ1wGW6DN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luca-Skyline/check4mate/blob/main/Chess_Piece_CNN_Model_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10/29/2023 Luca DalCanto\n",
        "\n",
        "# Chess Piece Convolutional Neural Network (CNN)\n",
        "The code contained in this jupyter notebook was used to create the Deep Learning image classification model used in check4mate, an app in development by Luca DalCanto.\n",
        "\n",
        "This code uses YOLOv5, a leading Neural Network for object detection and segmentation, but uses it instead for image classification. A dataset with around 25000 images is loaded from Roboflow, with each image labeled as one of 13 classes (6 pieces of two colors, plus the \"empty square\" class). The \"medium\" size of YOLOv5 model is fit with this data over 40 epochs, and the .pt file is then exported for use in my app.\n",
        "\n",
        "### Data\n",
        "\n",
        "You can find the dataset I used on Roboflow: https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4. This is my Roboflow project, but the images themselves are attributed to someone else (see below).\n",
        "\n",
        "This data has been preprocessed and augmented with the following properties:\n",
        "\n",
        "*   Preprocessing: Grayscale\n",
        "*   Preprocessing: Resize to 224x224 pixels (this should not do anything with my particular dataset but it's a good safety)\n",
        "*   Augmentation: 90Â°, 180Â°, 270Â° Rotation\n",
        "*   Augmentation: Brightness 20%\n",
        "*   Augmentation: Exposre 4%\n",
        "*   Augmentation: Blur 0.3px\n",
        "\n",
        "The preprocessing homogenizes the images, and the augmentation allows to have more images by duplicating some of the images with changes such as rotation and shear (the CNN needs to be able to identify a chess piece from any overhead angle).\n",
        "\n",
        "Data attributed to Daylen Yang under the Open Data Commons Attribution License: http://opendatacommons.org/licenses/by/1.0/.\n",
        "Thank you so much Daylen Yang!\n",
        "\n",
        "This data has been adapted for this specific dataset. By the nature of the Open Data Commons Attribution License, this \"new\" dataset found here is also protected by the same license. This means you can use this data, but you need to attribute and any modified form of the data must also be released under the same license.\n",
        "\n",
        "For more info on the raw data, please see Daylen Yang's github repo: https://github.com/daylen/chess-id\n",
        "\n",
        "Thanks! <br>\n",
        "Luca DalCanto, <br>\n",
        "Skyline High School, SLC, UT"
      ],
      "metadata": {
        "id": "xuM5MvoDjNQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t23YMrPsDKw",
        "outputId": "d5eed381-337f-498b-b130-5824e54db734"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-294-gdb125a20 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we're in the right directory to download our custom dataset\n",
        "import os\n",
        "os.makedirs(\"../datasets/\", exist_ok=True)\n",
        "%cd ../datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltwOos0nsFws",
        "outputId": "9dbac189-b39c-43d5-9692-8f64eef8b092"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## For safety reason, as this is a public colab, the API Key has been removed. To proceed, copy and paste the download code from Roboflow into this cell\n",
        "# https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4\n",
        "\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"INSERT KEY HERE\")\n",
        "# project = rf.workspace(\"luca-dalcanto-lrlwg\").project(\"chess-piece-detector-sv3nm\")\n",
        "# version = project.version(6)\n",
        "# dataset = version.download(\"folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DkQGDwIvsIkE",
        "outputId": "bf2b58d6-e7fd-4c9f-fd5f-dc519788eb33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.23-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna"
                ]
              },
              "id": "8fa896521e294a5ba9e38c7680341c6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Chess-Piece-Detector-6 to folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63960/63960 [00:00<00:00, 64743.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Chess-Piece-Detector-6 in folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13585/13585 [00:01<00:00, 8596.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the dataset name to the environment so we can use it in a system call later\n",
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"Chess-Piece-Detector-4\"] = dataset_name"
      ],
      "metadata": {
        "id": "Qo0nMZOCsX2H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from genericpath import isfile\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "for my_dir in os.listdir('/content/datasets/Chess-Piece-Detector-6/train'):\n",
        "  num_files = 0\n",
        "  for filename in os.listdir('/content/datasets/Chess-Piece-Detector-6/train/' + my_dir):\n",
        "    num_files += 1\n",
        "  print(my_dir,': ', num_files)\n"
      ],
      "metadata": {
        "id": "zM0JuD9wO1bm",
        "outputId": "6d7b6dda-7de5-4666-d5af-9d2f87adce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wn :  1155\n",
            "wr :  438\n",
            "bn :  1182\n",
            "wk :  624\n",
            "bq :  833\n",
            "empty :  1119\n",
            "wp :  1296\n",
            "wb :  1191\n",
            "bb :  1214\n",
            "bp :  1395\n",
            "br :  591\n",
            "wq :  693\n",
            "bk :  621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "!python classify/train.py --model yolov5m-cls.pt --data Chess-Piece-Detector-6 --epochs 50 --img 224 --pretrained weights/yolov5m-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz6Dk1UKsvwJ",
        "outputId": "613ece1e-0555-46bf-cb80-5d083a049121"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-03-12 22:32:44.266637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-12 22:32:44.266702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-12 22:32:44.268114: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5m-cls.pt, data=Chess-Piece-Detector-6, epochs=50, batch_size=64, imgsz=224, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5m-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-294-gdb125a20 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Model summary: 212 layers, 11693293 parameters, 11693293 gradients, 30.9 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 46 weight(decay=0.0), 47 weight(decay=5e-05), 47 bias\n",
            "Image sizes 224 train, 224 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp3\u001b[0m\n",
            "Starting yolov5m-cls.pt training on Chess-Piece-Detector-6 dataset with 13 classes for 50 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
            "      1/50     2.16G         2.1        2.54       0.222       0.616: 100% 193/193 [00:51<00:00,  3.77it/s]\n",
            "      2/50     2.71G        1.81        2.03       0.364       0.812: 100% 193/193 [00:51<00:00,  3.75it/s]\n",
            "      3/50     2.71G        1.71        1.68       0.412        0.98: 100% 193/193 [00:51<00:00,  3.77it/s]\n",
            "      4/50     2.71G        1.62        1.58       0.502       0.961: 100% 193/193 [00:52<00:00,  3.68it/s]\n",
            "      5/50     2.71G        1.53        1.48       0.512       0.985: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "      6/50     2.71G        1.45        1.56       0.569        0.95: 100% 193/193 [00:52<00:00,  3.68it/s]\n",
            "      7/50     2.71G        1.36        1.28       0.659       0.996: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "      8/50     2.71G         1.3           2       0.426       0.888: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "      9/50     2.71G        1.24        2.11       0.386       0.783: 100% 193/193 [00:52<00:00,  3.66it/s]\n",
            "     10/50     2.71G        1.19        1.19       0.741       0.986: 100% 193/193 [00:51<00:00,  3.72it/s]\n",
            "     11/50     2.71G        1.16        1.19       0.678       0.987: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "     12/50     2.71G        1.13       0.969       0.841       0.997: 100% 193/193 [00:52<00:00,  3.64it/s]\n",
            "     13/50     2.71G        1.11         1.7       0.598       0.913: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     14/50     2.71G        1.07        1.45       0.653        0.94: 100% 193/193 [00:51<00:00,  3.75it/s]\n",
            "     15/50     2.71G        1.05        1.16        0.73        0.99: 100% 193/193 [00:53<00:00,  3.63it/s]\n",
            "     16/50     2.71G        1.02       0.968       0.834       0.991: 100% 193/193 [00:50<00:00,  3.80it/s]\n",
            "     17/50     2.71G           1       0.988       0.848       0.985: 100% 193/193 [00:52<00:00,  3.71it/s]\n",
            "     18/50     2.71G       0.996       0.772       0.922       0.997: 100% 193/193 [00:52<00:00,  3.68it/s]\n",
            "     19/50     2.71G       0.953       0.757       0.928           1: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "     20/50     2.71G        0.95       0.735       0.927       0.998: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     21/50     2.71G       0.928       0.833       0.904       0.999: 100% 193/193 [00:53<00:00,  3.62it/s]\n",
            "     22/50     2.71G       0.913       0.647       0.979           1: 100% 193/193 [00:52<00:00,  3.71it/s]\n",
            "     23/50     2.71G         0.9       0.732       0.947           1: 100% 193/193 [00:52<00:00,  3.65it/s]\n",
            "     24/50     2.71G       0.896       0.682       0.957       0.999: 100% 193/193 [00:52<00:00,  3.70it/s]\n",
            "     25/50     2.71G       0.885       0.853       0.879       0.997: 100% 193/193 [00:53<00:00,  3.64it/s]\n",
            "     26/50     2.71G       0.875       0.715       0.937           1: 100% 193/193 [00:52<00:00,  3.66it/s]\n",
            "     27/50     2.71G       0.869       0.636        0.98           1: 100% 193/193 [00:52<00:00,  3.71it/s]\n",
            "     28/50     2.71G       0.851       0.654       0.967       0.999: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "     29/50     2.71G       0.848       0.649       0.974           1: 100% 193/193 [00:52<00:00,  3.64it/s]\n",
            "     30/50     2.71G       0.836       0.625       0.978           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     31/50     2.71G       0.823       0.606       0.989           1: 100% 193/193 [00:50<00:00,  3.85it/s]\n",
            "     32/50     2.71G       0.815       0.605        0.99           1: 100% 193/193 [00:52<00:00,  3.69it/s]\n",
            "     33/50     2.71G       0.816       0.596       0.991           1: 100% 193/193 [00:51<00:00,  3.72it/s]\n",
            "     34/50     2.71G       0.805       0.599       0.991           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     35/50     2.71G       0.803       0.606       0.983           1: 100% 193/193 [00:52<00:00,  3.69it/s]\n",
            "     36/50     2.71G       0.786       0.606       0.986           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     37/50     2.71G       0.774        0.59       0.989           1: 100% 193/193 [00:52<00:00,  3.67it/s]\n",
            "     38/50     2.71G       0.772       0.586       0.996           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     39/50     2.71G        0.77       0.589       0.988           1: 100% 193/193 [00:51<00:00,  3.71it/s]\n",
            "     40/50     2.71G       0.761       0.578       0.994           1: 100% 193/193 [00:52<00:00,  3.65it/s]\n",
            "     41/50     2.71G       0.749       0.578       0.995           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     42/50     2.71G        0.74       0.583       0.995           1: 100% 193/193 [00:51<00:00,  3.72it/s]\n",
            "     43/50     2.71G        0.74       0.575       0.996           1: 100% 193/193 [00:52<00:00,  3.66it/s]\n",
            "     44/50     2.71G       0.736       0.572       0.997           1: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "     45/50     2.71G       0.729       0.572       0.993           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "     46/50     2.71G       0.721       0.576       0.994           1: 100% 193/193 [00:51<00:00,  3.72it/s]\n",
            "     47/50     2.71G        0.71       0.573       0.995           1: 100% 193/193 [00:51<00:00,  3.74it/s]\n",
            "     48/50     2.71G       0.701        0.57       0.997           1: 100% 193/193 [00:52<00:00,  3.66it/s]\n",
            "     49/50     2.71G       0.701       0.569       0.997           1: 100% 193/193 [00:51<00:00,  3.72it/s]\n",
            "     50/50     2.71G       0.694       0.569       0.995           1: 100% 193/193 [00:51<00:00,  3.73it/s]\n",
            "\n",
            "Training complete (0.728 hours)\n",
            "Results saved to \u001b[1mruns/train-cls/exp3\u001b[0m\n",
            "Predict:         python classify/predict.py --weights runs/train-cls/exp3/weights/best.pt --source im.jpg\n",
            "Validate:        python classify/val.py --weights runs/train-cls/exp3/weights/best.pt --data /content/datasets/Chess-Piece-Detector-6\n",
            "Export:          python export.py --weights runs/train-cls/exp3/weights/best.pt --include onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp3/weights/best.pt')\n",
            "Visualize:       https://netron.app\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights /content/yolov5/runs/train-cls/exp2/weights/best.pt --source /content/somePiece.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzjKQfvRs8mF",
        "outputId": "ebb07789-f2bd-4aad-dd12-5898349df0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['/content/yolov5/runs/train-cls/exp2/weights/best.pt'], source=/content/somePiece.png, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-283-g875d9278 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/classify/predict.py\", line 238, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/classify/predict.py\", line 233, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/classify/predict.py\", line 102, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 370, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 78, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train-cls/exp2/weights/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov5s-cls.pt resnet50.pt efficientnet_b0.pt --include onnx engine --img 224"
      ],
      "metadata": {
        "id": "0mX3DNYDLsrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}